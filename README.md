# hw1_ml_design


## описание пайплайна:

в airflow создаются даги:
   - delete_bucket: удаляет bucket movielens
   - create_bucket: Создает bucket movielens
   - download_and_split: скачивает данные в директорию airflow/data, распаковывает, делит на train и test
     , закидывает данные в bucket
   - spark_process: подключается к spark, который делает обработку данных а именно:
     Считывает в pandas, обучает базовую модель ALS, записывает саму модель в bucket,
     валидирует модель и записывает результат метрики в ./airflow/data/metrics.json

## как запускать:
1)из корня репозитория:
docker compose build; docker compose up -d

2) далее необходимо перейти к airflow: localhost:8080/ и настроить admin.commection:
   <img width="1502" alt="image" src="https://github.com/user-attachments/assets/2ecb8c14-3262-4d70-a81d-4fcb31779b16" />

это нужно для подключения к spark

3) далее необходимо найти dag orchestrate_dags и выполнить его. Он запустит по очереди все даги, вот пример обработки:
   <img width="1504" alt="image" src="https://github.com/user-attachments/assets/333d3f5b-bf29-4f99-af09-2d4937fbc611" />

(на картинке последний даг завершился с ошибкой, однако это баг, весь пайплайн работает и последний даг выполняет последнее действие:
записывает метрику в файл: {"rmse": 0.7182586038474316}

можно вызвать отдельно даг, который делает connect к spark, он успешно завершится:
<img width="1504" alt="image" src="https://github.com/user-attachments/assets/cf9f80f2-26a0-44c6-b83f-0f9938583fd8" />




Что можно (нужно) исправить:
1) Во первых я скачиваю и в контейнер airflow и в контейнер spark эти jar файлы (как вариант
   научиться прокидывать их с контейнера в контейнер, либо скачать на локалку и прокинуть в оба контейнера)

2) по хорошему надо удалять скачанные временные данные из data
3) в одном спарк скрипте выполняется: тренировка + сохранение модели + валидация. Необходимо конечно разделять
4) Некоторые даги тоже слишком много функций выполняют, надо разделять
5) разделение на train и test идет просто отсечением, можно умнее
6) увеличить количество выделяемой памяти воркерам + скачивать большой датасет
